![banner](banner.png)

![Python-3.8](https://img.shields.io/badge/Python-3.8-green?style=for-the-badge)
![Flask](https://img.shields.io/badge/Flask-1.1.5-lightblue?style=for-the-badge)
![PR](https://img.shields.io/badge/PRs-welcome-red?style=for-the-badge)
![Open Source](https://img.shields.io/badge/%20-Open%20Source-blueviolet?style=for-the-badge)
![Club](https://img.shields.io/badge/%20-MLSC%20VIT-darkblue?style=for-the-badge)

## Important Links
- [Document for Project Progress](https://docs.google.com/document/d/1pv3LflkUZkE4ew86rI3FuPUinsb6uap9_0paiG8Z1AU/edit?usp=sharing)
- [Dataset Used](https://www.kaggle.com/fedesoriano/heart-failure-prediction)
- [Website](https://ai-pathologist.my.canva.site/)

<br>

## Approaches
### [Approach 1 - Manomay Jamble](https://colab.research.google.com/drive/1Jq6pApDzjtzzg638spIHKC6dU9tIU3uT?usp=sharing)
- Explored dataset - found many zero values in Cholesterol and one in RestingBP
- Applied decision tree and random forest on raw data
- Got an accuracy of around 85%
- Can replace Cholesterol values with mean retain info
- Another way to predict cholesterol values using other features

### [Approach 2 - Devanshu Dalal](https://colab.research.google.com/drive/1_QETqJhC4h_23JNs5v-O46ckJ1vsUkxM?usp=sharing)
- Explore dataset to find trends in data
- Preprocess data to remove unrealistic values and didone hot encoding
- Tried various models like Random Forest, Decision Tree, KNN, Logistic regression,  Naive Bayes
- Got an accuracy of 90 percent on logistic regression and naive bayes 
- Would work on preprocessing and improving accuracy

### [Approach 3 - Shreyash Deshmukh](#)
- Explored data set and did EDA of data
- Cleaned the data by using data cleaning techniques
- Tried some machine learning models and found the appropriate model according to data
- Got an accuracy of 85.5 percent by KNN model
- Done with the creating input function for the user to input the data

<br>

## Contributors
- Omkar Prabhune
- Shreyash Deshmukh
- Isha Deshpande
- Manomay Jamble
- Devanshu Dalal
